---
layout: fall2020/page
permalink: /fall2020/readings/
title: Readings
---

Week 2:
1. Baltrusaitis et al., [Multimodal Machine Learning: A Survey and Taxonomy](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/keln1op3u2j5z1). TPAMI 2018
2. Bengio et al., [Representation Learning: A Review and New Perspectives](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/keln1obkjer5ym). TPAMI 2013

Week 3:
1. Zeiler and Fergus, [Visualizing and Understanding Convolutional Networks](https://piazza.com/class_profile/get_resource/jjyt9xcoem64k5/jlvnkpiszoo26g). ECCV 2014
2. Selvaraju et al., [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://piazza.com/class_profile/get_resource/jjyt9xcoem64k5/jlscu1vibjh3s8). ICCV 2017
3. Karpathy et al., [Visualizing and Understanding Recurrent Networks](https://arxiv.org/pdf/1506.02078.pdf). arXiv 2015
4. Khandelwal et al., [Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context](https://arxiv.org/pdf/1805.04623.pdf). ACL 2018

Week 4:
1. Owens et al., [Audio-Visual Scene Analysis with Self-Supervised Multisensory Features](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzq9wixp4h5). ECCV 2018
2. Wang et al., [Learning Deep Structure-Preserving Image-Text Embeddings](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzks1fk13yc). CVPR 2016
3. Eisenschtat and Wolf, [Linking Image and Text with 2-Way Nets](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzj5yckj3wi). CVPR 2017
4. Zhang et al., [AE2-Nets: Autoencoder in Autoencoder Networks](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzkwln5e3yh). CVPR 2019

Week 5:
1. Anderson et al., [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv9b4ykqt6ou). CVPR 2018
2. Wiegreffe and Pinter, [Attention is not not Explanation](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv9jk378q774). EMNLP 2019
3. Le et al., [Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv97aseti6i1). ACL 2019 
4. Tan and Bansal, [LXMERT: Learning Cross-Modality Encoder Representations from Transformers](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv96gl6at6gg). EMNLP 2019

Week 7:
1. Mao et al., [The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision](https://arxiv.org/pdf/1904.12584.pdf). ICLR 2019
2. Kottur et al., [Visual Coreference Resolution in Visual Dialog using Neural Module Networks](https://arxiv.org/pdf/1809.01816.pdf). ECCV 2018
3. Cuturi and Blondel, [Soft-DTW: a Differentiable Loss Function for Time-Series](https://arxiv.org/pdf/1703.01541.pdf). ICML 2017
4. Zhu et al., [Toward Multimodal Image-to-Image Translation](https://papers.nips.cc/paper/6650-toward-multimodal-image-to-image-translation.pdf). NeurIPS 2017

Week 8:
1. Sigurdsson et al., [Asynchronous Temporal Fields for Action Recognition](https://arxiv.org/abs/1612.06371). CVPR 2017
2. Dai et al., [Detecting Visual Relationships with Deep Relational Networks](https://arxiv.org/abs/1704.03114). CVPR 2017 
3. Wu and Goodman, [Multimodal Generative Models for Scalable Weakly-Supervised Learning](https://arxiv.org/abs/1802.05335). NeurIPS 2018
4. Zhu et al., [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593). ICCV 2017

Week 9:
1. Lee et al., [Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks](https://arxiv.org/pdf/1907.13098.pdf). ICRA 2019
2. Luketina at al., [A Survey of Reinforcement Learning Informed by Natural Language](https://arxiv.org/pdf/1906.03926.pdf). IJCAI 2019
3. Das et al., [Neural Modular Control for Embodied Question Answering](https://arxiv.org/pdf/1810.11181.pdf). CoRL 2018
4. Dai et al., [Towards Diverse and Natural Image Descriptions via a Conditional GAN](https://arxiv.org/pdf/1703.06029.pdf). ICCV 2019

Week 10:
1. Pang and Wang, [Guessing State Tracking for Visual Dialogue](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kh0rhs63hoo20w). ECCV 2020
2. Hu et al., [Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kh0rhrfwmxk2o5). CVPR 2020
3. Hudson and Manning, [Learning by Abstraction: The Neural State Machine](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kh0rhm94vtu209). NeurIPS 2019
4. Hill et al., [Grounded Language Learning Fast and Slow](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kh0rhdrt5leu0). 2020

Week 12:
1. Anderson et al., [Sim-to-Real Transfer for Vision-and-Language Navigation](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/khkw1kazr8f4pa). CoRL 2020
2. Blukis et al., [Mapping Navigation Instructions to Continuous Control Actions with Position-Visitation Prediction](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/khkw2deazjf7n3). CoRL 2018
3. Kojima et al., [What is Learned in Visually Grounded Neural Syntax Acquisition](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/khkw3h27w5720a). ACL 2020
4. Zhu et al., [The Return of Lexical Dependencies: Neural Lexicalized PCFGs](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/khkw3zkbfz3323). TACL 2020 

Week 14:
1. Alikhani et al., [Clue: Cross-modal Coherence Modeling for Caption Generation](https://arxiv.org/abs/2005.00908). ACL 2020
2. Agarwal et al., [History for Visual Dialog: Do we really need it?](https://arxiv.org/pdf/2005.07493.pdf). ACL 2020
3. Barocas and Selbst, [Big Dataâ€™s Disparate Impact](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/ki64rsjlib766). California Law Review 2016
4. Hovy and Spruit, [The Social Impact of Natural Language Processing](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/ki64qpvx44k5ei). ACL 2016
