<!DOCTYPE html>
<html>
  <head>
  <meta charset="UTF-8">
  <meta http-equiv="content-language" content="en">
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>11-777 MMML | Readings</title>
  <meta name="description" content="11-777 - Multimodal Machine Learning - Carnegie Mellon University - Fall 2020
">

  <link rel="shortcut icon" href="/mmml-course/assets/img/favicon.ico">

  <link rel="stylesheet" href="/mmml-course/assets/css/main.css">
  <link rel="canonical" href="/mmml-course/fall2020/readings/">

  
  <!-- Load Latex JS -->
  <script src="https://cdn.jsdelivr.net/npm/latex.js@0.11.1/dist/latex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/latex.js@0.11.1/dist/latex.component.js"></script>
  
</head>


  <body>
    <link rel="stylesheet" href="/mmml-course/assets/css/header_styles.css">
<script src="/mmml-course/assets/js/header_scripts.js"></script>

<header class="site-header">
    <div class="wrapper">
        <div class="header-flex">
            <div class="dropdown">
                <button onclick="toggleDropdown()" class="dropbtn">11-777 MMML</button>
                <div id="myDropdown" class="dropdown-content">
                    <a href="/mmml-course/fall2023/">Fall2023</a>
                    <a href="/mmml-course/fall2022/">Fall2022</a>
                    <a href="/mmml-course/fall2020/">Fall2020</a>
                </div>
            </div>

            <nav class="site-nav">
                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                <label for="nav-trigger">
                    <span class="menu-icon">
                        <svg viewBox="0 0 18 15" width="18px" height="15px">
                            <path fill="#424242"
                                d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z" />
                            <path fill="#424242"
                                d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z" />
                            <path fill="#424242"
                                d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z" />
                        </svg>
                    </span>
                </label>

                <div class="trigger">
                    <a class="page-link" href="/mmml-course/fall2020/">home</a>
                    <a class="page-link" href="/mmml-course/fall2020/schedule/">schedule</a>
                    <a class="page-link" href="/mmml-course/fall2020/readings/">readings</a>
                    <a class="page-link" href="/mmml-course/fall2022/syllabus/">syllabus</a>
                    <a class="page-link" href="/mmml-course/fall2020/projects/">projects</a>
                </div>
            </nav>
        </div>
    </div>
</header>

    <div class="page-content">
      <div class="wrapper"><div class="post">

  <header class="post-header">
    <h1 class="post-title">Readings</h1>
    <h2 class="post-description"></h2>
  </header>

  <article class="post-content Readings clearfix">
    <p>Week 2:</p>
<ol>
  <li>Baltrusaitis et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/keln1op3u2j5z1">Multimodal Machine Learning: A Survey and Taxonomy</a>. TPAMI 2018</li>
  <li>Bengio et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/keln1obkjer5ym">Representation Learning: A Review and New Perspectives</a>. TPAMI 2013</li>
</ol>

<p>Week 3:</p>
<ol>
  <li>Zeiler and Fergus, <a href="https://piazza.com/class_profile/get_resource/jjyt9xcoem64k5/jlvnkpiszoo26g">Visualizing and Understanding Convolutional Networks</a>. ECCV 2014</li>
  <li>Selvaraju et al., <a href="https://piazza.com/class_profile/get_resource/jjyt9xcoem64k5/jlscu1vibjh3s8">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</a>. ICCV 2017</li>
  <li>Karpathy et al., <a href="https://arxiv.org/pdf/1506.02078.pdf">Visualizing and Understanding Recurrent Networks</a>. arXiv 2015</li>
  <li>Khandelwal et al., <a href="https://arxiv.org/pdf/1805.04623.pdf">Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context</a>. ACL 2018</li>
</ol>

<p>Week 4:</p>
<ol>
  <li>Owens et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzq9wixp4h5">Audio-Visual Scene Analysis with Self-Supervised Multisensory Features</a>. ECCV 2018</li>
  <li>Wang et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzks1fk13yc">Learning Deep Structure-Preserving Image-Text Embeddings</a>. CVPR 2016</li>
  <li>Eisenschtat and Wolf, <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzj5yckj3wi">Linking Image and Text with 2-Way Nets</a>. CVPR 2017</li>
  <li>Zhang et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzkwln5e3yh">AE2-Nets: Autoencoder in Autoencoder Networks</a>. CVPR 2019</li>
</ol>

<p>Week 5:</p>
<ol>
  <li>Anderson et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv9b4ykqt6ou">Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</a>. CVPR 2018</li>
  <li>Wiegreffe and Pinter, <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv9jk378q774">Attention is not not Explanation</a>. EMNLP 2019</li>
  <li>Le et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv97aseti6i1">Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems</a>. ACL 2019</li>
  <li>Tan and Bansal, <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv96gl6at6gg">LXMERT: Learning Cross-Modality Encoder Representations from Transformers</a>. EMNLP 2019</li>
</ol>

<p>Week 7:</p>
<ol>
  <li>Mao et al., <a href="https://arxiv.org/pdf/1904.12584.pdf">The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision</a>. ICLR 2019</li>
  <li>Kottur et al., <a href="https://arxiv.org/pdf/1809.01816.pdf">Visual Coreference Resolution in Visual Dialog using Neural Module Networks</a>. ECCV 2018</li>
  <li>Cuturi and Blondel, <a href="https://arxiv.org/pdf/1703.01541.pdf">Soft-DTW: a Differentiable Loss Function for Time-Series</a>. ICML 2017</li>
  <li>Zhu et al., <a href="https://papers.nips.cc/paper/6650-toward-multimodal-image-to-image-translation.pdf">Toward Multimodal Image-to-Image Translation</a>. NeurIPS 2017</li>
</ol>

<p>Week 8:</p>
<ol>
  <li>Sigurdsson et al., <a href="https://arxiv.org/abs/1612.06371">Asynchronous Temporal Fields for Action Recognition</a>. CVPR 2017</li>
  <li>Dai et al., <a href="https://arxiv.org/abs/1704.03114">Detecting Visual Relationships with Deep Relational Networks</a>. CVPR 2017</li>
  <li>Wu and Goodman, <a href="https://arxiv.org/abs/1802.05335">Multimodal Generative Models for Scalable Weakly-Supervised Learning</a>. NeurIPS 2018</li>
  <li>Zhu et al., <a href="https://arxiv.org/abs/1703.10593">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</a>. ICCV 2017</li>
</ol>

<p>Week 9:</p>
<ol>
  <li>Lee et al., <a href="https://arxiv.org/pdf/1907.13098.pdf">Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks</a>. ICRA 2019</li>
  <li>Luketina at al., <a href="https://arxiv.org/pdf/1906.03926.pdf">A Survey of Reinforcement Learning Informed by Natural Language</a>. IJCAI 2019</li>
  <li>Das et al., <a href="https://arxiv.org/pdf/1810.11181.pdf">Neural Modular Control for Embodied Question Answering</a>. CoRL 2018</li>
  <li>Dai et al., <a href="https://arxiv.org/pdf/1703.06029.pdf">Towards Diverse and Natural Image Descriptions via a Conditional GAN</a>. ICCV 2019</li>
</ol>

<p>Week 10:</p>
<ol>
  <li>Pang and Wang, <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kh0rhs63hoo20w">Guessing State Tracking for Visual Dialogue</a>. ECCV 2020</li>
  <li>Hu et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kh0rhrfwmxk2o5">Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA</a>. CVPR 2020</li>
  <li>Hudson and Manning, <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kh0rhm94vtu209">Learning by Abstraction: The Neural State Machine</a>. NeurIPS 2019</li>
  <li>Hill et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kh0rhdrt5leu0">Grounded Language Learning Fast and Slow</a>. 2020</li>
</ol>

<p>Week 12:</p>
<ol>
  <li>Anderson et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/khkw1kazr8f4pa">Sim-to-Real Transfer for Vision-and-Language Navigation</a>. CoRL 2020</li>
  <li>Blukis et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/khkw2deazjf7n3">Mapping Navigation Instructions to Continuous Control Actions with Position-Visitation Prediction</a>. CoRL 2018</li>
  <li>Kojima et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/khkw3h27w5720a">What is Learned in Visually Grounded Neural Syntax Acquisition</a>. ACL 2020</li>
  <li>Zhu et al., <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/khkw3zkbfz3323">The Return of Lexical Dependencies: Neural Lexicalized PCFGs</a>. TACL 2020</li>
</ol>

<p>Week 14:</p>
<ol>
  <li>Alikhani et al., <a href="https://arxiv.org/abs/2005.00908">Clue: Cross-modal Coherence Modeling for Caption Generation</a>. ACL 2020</li>
  <li>Agarwal et al., <a href="https://arxiv.org/pdf/2005.07493.pdf">History for Visual Dialog: Do we really need it?</a>. ACL 2020</li>
  <li>Barocas and Selbst, <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/ki64rsjlib766">Big Dataâ€™s Disparate Impact</a>. California Law Review 2016</li>
  <li>Hovy and Spruit, <a href="https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/ki64qpvx44k5ei">The Social Impact of Natural Language Processing</a>. ACL 2016</li>
</ol>

  </article>

</div>
</div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Multimodal Machine Learning</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1" style="width:200px;">
        <ul class="contact-list">
          <li class="p-name">CMU MultiComp Lab</li></ul>
      </div>

      <div class="footer-col footer-col-2" style="width:200px;"><ul class="social-media-list"><li><a href="https://github.com/CMU-MultiComp-Lab" target="_blank"><i class="fab fa-github"></i> <span class="username">CMU-MultiComp-Lab</span></a></li><li><a href="https://www.youtube.com/channel/UCqlHIJTGYhiwQpNuPU5e2gg"  target="_blank"><i class="fab fa-youtube"></i> <span class="username">YouTube</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>&copy; Copyright 2023 Carnegie Mellon University. <br />
        Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.
</p>
      </div>
    </div>

  </div>

</footer>
 <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/mmml-course/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.js"></script>
<script src="/mmml-course/assets/js/katex.js"></script>



<!-- Load Anchor JS -->
<script src="//cdnjs.cloudflare.com/ajax/libs/anchor-js/3.2.2/anchor.min.js"></script>
<script>
  anchors.options.visible = 'hover';
  anchors.add('article h2, article h3, article h4, article h5, article h6');
</script>



<!-- Adjust LaTeX JS -->
<script src="/mmml-course/assets/js/latex.js"></script>


<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/mmml-course/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/mmml-course/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-131744305-1', 'auto');
ga('send', 'pageview');
</script>

  </body>
</html>
